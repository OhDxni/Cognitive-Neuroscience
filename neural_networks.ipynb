{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6dc08c-85a6-4e33-97ad-71f09c322769",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### DISCLAIMER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676dd4ce-23fa-440a-985b-875ab2019ceb",
   "metadata": {},
   "source": [
    "Most of the code has been aquired through the following to sources:\n",
    "1. https://www.tensorflow.org/datasets/keras_example\n",
    "2. https://www.tensorflow.org/tutorials/images/cnn\n",
    "\n",
    "With the help of the above two sources the neural netowrks below were created. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f937d6af",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25898cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT THE LINE BELOW TO INSTALL LIBRARIES\n",
    "# !pip install tensorflow tensorflow-datasets matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8d62c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76a9f8d",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b8e175",
   "metadata": {},
   "source": [
    "### Loading the MINST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07540504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the dataset using tfds\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],  # Splits the dataset up into a train part and test part\n",
    "    shuffle_files=True,       # Shuffles files so that model doesn't learn unintended patterns\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55432fb9",
   "metadata": {},
   "source": [
    "### Normalising images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b46c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalises the pixels of an image, so that it can be used for training\n",
    "def normalize_img(image, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255., label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b80a7ef",
   "metadata": {},
   "source": [
    "### Preparing the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f689cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)  # Normalises image\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)            # Shuffles data\n",
    "ds_train = ds_train.cache()                                                  # Saves normalisation of image/dataset so that it doesn't have to be normalised again\n",
    "ds_train = ds_train.batch(50)                                                # Trains with x amount of samples immediately each time instead of e.g. 1\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)                               # Prepare next dataset as current one is being used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbfe2b7",
   "metadata": {},
   "source": [
    "### Preparing the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c7e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same explanation as for training the model\n",
    "ds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714ce1c5",
   "metadata": {},
   "source": [
    "## Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba345d36",
   "metadata": {},
   "source": [
    "### Fully Connected Neural Network (1 hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89a906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model\n",
    "model_FCNN_1 = tf.keras.models.Sequential([         # Define model type; sequential goes through all layers one after another\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),  # First layer\n",
    "    tf.keras.layers.Dense(128, activation='relu'),  # Hidden layer; .Dense forces it to be fully connected\n",
    "    tf.keras.layers.Dense(10)                       # Final output layer; \"10\" because we have 10 types of images (numbers 0 - 9).\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model_FCNN_1.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),                             # Algorithm to update model's weights during training; backpropagation!!\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  # Loss function; evaluate model's prediction\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "model_FCNN_1.fit(\n",
    "    ds_train,                 # Uses dataset to train model\n",
    "    epochs=6,                 # Amount of times a dataset is trained on\n",
    "    validation_data=ds_test,  # Tests the trained model; will influence each new epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2996924f",
   "metadata": {},
   "source": [
    "### Fully Connected Neural Network (3 hidden layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12623418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model\n",
    "model_FCNN_2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),  # First hidden layer\n",
    "    tf.keras.layers.Dense(128, activation='relu'),  # Second hidden layer\n",
    "    tf.keras.layers.Dense(128, activation='relu'),  # Third hidden layer\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model_FCNN_2.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),                             # Algorithm to update model's weights during training; backpropagation!!\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  # Loss function; evaluate model's prediction\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "model_FCNN_2.fit(\n",
    "    ds_train,                 # Uses dataset to train model\n",
    "    epochs=6,                 # Amount of times a dataset is trained on\n",
    "    validation_data=ds_test,  # Tests the trained model; will influence each new epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7bafae",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8ca4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv2D(32 is a single layer with 32 filters; these filters go over a (3, 3) part of the image and create feature maps\n",
    "# MaxPooling2D reduces size of the information the feature maps gathered, while keeping all the relevant information\n",
    "model_CNN = models.Sequential()\n",
    "model_CNN.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_CNN.add(layers.MaxPooling2D((2, 2)))\n",
    "model_CNN.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_CNN.add(layers.MaxPooling2D((2, 2)))\n",
    "model_CNN.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_CNN.add(layers.Flatten())                      # Transforms 2D feature map into 1D\n",
    "model_CNN.add(layers.Dense(128, activation='relu'))  # Connect \"neurons\" from convolutional layers to dense layer to perform classification\n",
    "model_CNN.add(layers.Dense(10))                      # Output layer\n",
    "\n",
    "# Compiling the model\n",
    "model_CNN.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),                             # Algorithm to update model's weights during training; backpropagation!!\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  # Loss function; evaluate model's prediction\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "model_CNN.fit(\n",
    "    ds_train,                 # Uses dataset to train model\n",
    "    epochs=6,                 # Amount of times a dataset is trained on\n",
    "    validation_data=ds_test,  # Tests the trained model; will influence each new epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85f07c4",
   "metadata": {},
   "source": [
    "### Testing the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eedd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call each network, and store results in variables\n",
    "test_loss_FCCN_1, test_accuracy_FCNN_1 = model_FCNN_1.evaluate(ds_test)\n",
    "test_loss_FCCN_2, test_accuracy_FCNN_2 = model_FCNN_2.evaluate(ds_test)\n",
    "test_loss_CNN, test_accuracy_CNN = model_CNN.evaluate(ds_test)\n",
    "\n",
    "# Prints results of testing per network\n",
    "print(f\"{'FCNN_1\\'s accuracy:':<20}{test_accuracy_FCNN_1:.4f}\")\n",
    "print(f\"{'FCNN_2\\'s accuracy:':<20}{test_accuracy_FCNN_2:.4f}\")\n",
    "print(f\"{'CNN\\'s accuracy:':<20}{test_accuracy_CNN:.4f}\\n\")\n",
    "\n",
    "print(f\"{'FCNN_1\\'s loss:':<16}{test_loss_FCCN_1:.4f}\")\n",
    "print(f\"{'FCNN_2\\'s loss:':<16}{test_loss_FCCN_2:.4f}\")\n",
    "print(f\"{'CNN\\'s loss:':<16}{test_loss_CNN:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c64d03-d79c-41dd-842c-a2c9fca3111e",
   "metadata": {},
   "source": [
    "### Accuracy and loss plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd215d5-5869-4531-a41f-0498011e2857",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"FCNN_1\", \"FCNN_2\", \"CNN\"]\n",
    "\n",
    "# Create subplots to nicely show plots next to each other\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4), dpi=100, gridspec_kw={'wspace': 0.4})\n",
    "\n",
    "# Accuracy Plot\n",
    "accuracy = [test_accuracy_FCNN_1, test_accuracy_FCNN_2, test_accuracy_CNN]\n",
    "axes[0].bar(models, accuracy, color=[\"red\", \"purple\", \"blue\"])\n",
    "axes[0].set_xlabel(\"Models\", fontsize=16)\n",
    "axes[0].set_ylabel(\"Accuracy\", fontsize=16) \n",
    "axes[0].set_title(\"Model Accuracy Comparison\", fontsize=16)\n",
    "axes[0].set_ylim(0.90, 1)  # Zooms in on upper half of y-axis\n",
    "axes[0].tick_params(axis='x', labelsize=12)\n",
    "axes[0].tick_params(axis='y', labelsize=14)\n",
    "\n",
    "# Loss Plot\n",
    "loss = [test_loss_FCCN_1, test_loss_FCCN_2, test_loss_CNN]\n",
    "axes[1].bar(models, loss, color=[\"red\", \"purple\", \"blue\"])\n",
    "axes[1].set_xlabel(\"Models\", fontsize=16)\n",
    "axes[1].set_ylabel(\"Loss\", fontsize=16)\n",
    "axes[1].set_title(\"Model Loss Comparison\", fontsize=16)\n",
    "axes[1].tick_params(axis=\"x\", labelsize=12)\n",
    "axes[1].tick_params(axis=\"y\", labelsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df99d84-10f8-4bb6-86bc-05b508c4ad97",
   "metadata": {},
   "source": [
    "### Data analysis\n",
    "In the plots above it is evident that the CNN performs the best based on the provided training and testing data. The main reason probably lies in the way Fully Connected Artifical Networks (FCNN's) and Convolutional Neural Networks (CNN's) process image data. \n",
    "\n",
    "For FCNN's, the pixel data is received and each seperate pixel is analysed. Then, based on common features and patterns, an attempt is made to indentify images. For CNN's this is different: CNN's process image data as 2D arrays (this is also visible in the code above; that's why e.g. .Flatten() had to be used). Seeing as CNN's take into account where each pixel belongs, instead of analysing each pixel seperately, it will most likely detect more accurate patterns, thereby increasing its accuracy in the testing epoches. This would also explain why its loss is lower compared to the other two; the CNN model is better able to generalise to new data. For the FCNN models, the accuracy is not that far behind the CNN's accuracy, but the loss of FCNN_1 and especially FCNN_2 is way higher than the one for CNN. A higher loss will indicate something like over- or underfitting. FCNN_2 has two more hidden layers compared to FCNN_1, thus meaning FCNN_2 has more parameters to work with, which does not seem to work for the provided data. \n",
    "\n",
    "Therefore, CNN is able to best generalise to new data, while FCNN_1 and FCNN_2 fail to do this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
